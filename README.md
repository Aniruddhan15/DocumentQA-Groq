# 🧠 ChatGroq with LLaMA3 Demo (RAG App)

This is a **Retrieval-Augmented Generation (RAG)** based web application built using **Streamlit**, powered by **LangChain**, **FAISS**, **OpenAI embeddings**, and **Groq's LLaMA3 model**. Users can upload PDF documents and ask questions — the app retrieves relevant chunks from the documents and uses the LLM to answer them.

---

## 🚀 Features

- 🔍 Load and chunk multiple PDFs
- 🔗 Store document embeddings in FAISS
- 📡 Retrieve relevant information for any user question
- 🤖 Answer using Groq’s blazing-fast LLaMA3 model
- 📄 View the exact document chunks used for answering

---

## 🧩 Tech Stack

| Tool/Library       | Purpose                                |
|--------------------|----------------------------------------|
| Streamlit          | Frontend Web Interface                 |
| LangChain          | Building chains (retrieval + LLM)      |
| FAISS              | Vector similarity search               |
| OpenAI             | Embeddings model for text vectors      |
| Groq               | LLM backend for answering              |
| dotenv             | Load API keys securely                 |

---


